{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering is the process of designing and optimizing prompts to guide AI models to generate desired responses. It's a way to help AI models understand the intent of a request and respond in a meaningful way.\n",
    "\n",
    "\n",
    "* Write, refine, and optimize prompts\n",
    "\n",
    "* perfect the interactions between humans and AI\n",
    "\n",
    "* Continuously monitor prompts\n",
    "\n",
    "* Maintain up to date Prompt library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is AI: \n",
    "\n",
    "Artifical intelligence is the simulation of human intelligence processes by machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative artificial intelligence (AI), also known as generative AI or GenAI, is a type of AI that uses machine learning to create new content: \n",
    "\n",
    "## What it does\n",
    "\n",
    "Generative AI can create new content like images, videos, music, text, and audio. It can also learn complex subjects like programming languages, art, chemistry, and biology. \n",
    "\n",
    "## How it works\n",
    "Generative AI uses machine learning models trained on large amounts of data to learn patterns and predict what comes next in a pattern. It doesn't use algorithms to find existing sources like internet searches does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistics\n",
    "\n",
    "It is the study of Language\n",
    "\n",
    "![Linguistics Study Areas](linguistics.png)\n",
    "\n",
    "- **Phonetics**: The study of how speech sounds are produced and perceived.\n",
    "- **Phonology**: The study of sound patterns and changes.\n",
    "- **Morphology**: The study of word structure.\n",
    "- **Syntax**: The study of sentence structure.\n",
    "- **Semantics**: The study of linguistic meaning.\n",
    "- **Pragmatics**: The study of how language is used in context.\n",
    "- **Historical Linguistics**: The study of language change.\n",
    "- **Sociolinguistics**: The study of the relationship between language and society.\n",
    "- **Computational Linguistics**: The study of how computers process human language.\n",
    "- **Psycholinguistics**: The study of how humans acquire and use language.\n",
    "\n",
    "\n",
    "# Linguistics are key to prompt engineering\n",
    "\n",
    "understanding the nuances of language and how it iis used in different contexts is crucial for crafting effective prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to check the length of Tokens while working with OpenAI models : https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Prompts\n",
    "\n",
    "![Types of Prompts](prompts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit prompts: Explicit prompts are direct and specific instructions given to the language model. These prompts typically involve a specific task or goal, and the language model is expected to generate text that directly addresses this task or goal.\n",
    "\n",
    "![Explicit Prompts](explicit.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Prompts : Conversational prompting unlocks intuitive AI collaboration through simple, interactive chat. Blending user guidance with machine intelligence, this natural approach lets anyone discover capabilities. \n",
    "\n",
    "![Conversational Prompts](conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructional Prompts : An instructional prompt is a directive used in AI communication, where the user provides explicit instructions to guide the AI's response. Unlike general or open-ended questions, instructional prompts are specific, directing the AI not just on what information is needed but often how to present it.\n",
    "\n",
    "![Inst Prompts](INST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Based Prompts: Contextual prompts, also known as in-context prompting or prompt engineering, are a technique that provides background information or context within a prompt to help an AI model generate a more relevant response. Contextual prompts help AI models understand the user's needs and create more personalized responses. For example, when using an LLM to generate a credit card recommendation, a contextual prompt can provide important signals to help the LLM make the right recommendation. \n",
    "\n",
    "![Context Prompts](context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Ended Prompts : An open-ended prompt is a question that encourages a respondent to provide a detailed answer rather than a simple \"yes\" or \"no\". Open-ended questions are often used to encourage exploration of a topic, and to help the asker understand the respondent's perspective.\n",
    "\n",
    "![Open Ended Prompts](open.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Mitigating Prompts : Bias mitigating prompts are prompts that are designed to reduce bias and promote fairness in AI language models (LLMs). \n",
    "\n",
    "![Bias Prompts](bias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation Prompts: Code generation prompts are input sequences that use artificial intelligence (AI) and machine learning (ML) to generate code based on a user's description:\n",
    "\n",
    "![Code Prompts](code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques used in Prompt Engineering\n",
    "\n",
    "![Techiques Prompts](technique.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting : Zero-shot prompting is a technique that uses a pre-trained AI model to perform a task without providing any specific training or examples. The model uses its general knowledge and patterns it learned during training to generate a response\n",
    "\n",
    "![Zero Prompts](zero.png)\n",
    "\n",
    "![Zero2 Prompts](zero2.png)\n",
    "\n",
    "![Zero3 Prompts](zero3.png)\n",
    "\n",
    "![Zero4 Prompts](zero4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Prompting: One-shot prompting is a prompt engineering technique that involves giving a Large Language Model (LLM) a single example to guide its response and perform a new task\n",
    "One-shot prompting is more informative than zero-shot prompting, but less so than few-shot prompting. It's particularly useful in language models, where it can generate a complete text or answer a question.\n",
    "\n",
    "![One Prompts](one.png)\n",
    "\n",
    "![One Prompts](one1.png)\n",
    "\n",
    "![One Prompts](one2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Prompting : Few-shot prompting\" in the context of large language models (LLMs) is a technique where you provide a small number of example inputs and outputs within the prompt to guide the model towards performing a specific task, essentially \"showing\" the LLM how to respond by giving it a handful of relevant examples, rather than relying solely on its general knowledge; this is particularly useful when you don't have a large amount of training data for fine-tuning the model on a specific task.\n",
    "\n",
    "![Few Prompts](few.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#groq_api_key=os.environ['GROQ_API_KEY']\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a financial advisor for People.\\nIn an easy way explain the basics of income tax'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "demo_template=\"\"\"I want you to act as a financial advisor for People.\n",
    "In an easy way explain the basics of {financial_concept}\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(\n",
    "    input_variables=['finacial_concept'],\n",
    "    template=demo_template\n",
    ")\n",
    "\n",
    "prompt.format(financial_concept='income tax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "#LLM Chain is needed to excute prompt template\n",
    "\n",
    "llm=OpenAI(temperature=0.7)\n",
    "chain1=LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nSure, no problem. As a financial advisor, my job is to help people understand and manage their finances. One important aspect of personal finance is income tax. So, let me explain the basics of income tax in an easy way.\\n\\nIncome tax is a tax that is imposed on the income you earn from your job, investments, and other sources. The amount of income tax you pay is based on your total income for the year. This means that the more money you earn, the higher your income tax will be.\\n\\nNow, there are different types of income tax in most countries. The most common are federal or national income tax and state or local income tax. The federal income tax is imposed by the national government, while state and local income taxes are imposed by your state or city government.\\n\\nTo determine how much income tax you owe, the government uses a system called a tax bracket. This means that your income is divided into different levels or brackets, and each bracket has a different tax rate. For example, if you earn $50,000 a year and your tax bracket is 20%, then you will pay 20% of your income in taxes, which would be $10,000.\\n\\nHowever, it's important to note that not all of your income is\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.run('income tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In an easy way translate following sentence 'How are you' into Hindi\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language Translator\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "lang_template='''In an easy way translate following sentence '{sentence}' into {target_language}'''\n",
    "\n",
    "lang_prompt=PromptTemplate(\n",
    "    input_variables=[\"sentence\",'target_language'],\n",
    "    template=lang_template\n",
    ")\n",
    "\n",
    "lang_prompt.format(sentence='How are you', target_language='Hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello How are you',\n",
       " 'target_language': 'Hindi',\n",
       " 'text': '\\n\\nनमस्ते क्या हाल है आपका? (Namaste kya haal hai aapka?)'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=LLMChain(llm=llm,prompt=lang_prompt)\n",
    "\n",
    "chain2({'sentence': \"Hello How are you\",'target_language':'Hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create the `FewShotPromptTemplate` object.\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\\n\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input='big'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small\\n\\nWord: fast\\nAntonym: slow'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
